<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="LeoHung.self(), ">

        <link rel="alternate"  href="http://leohung.net/feeds/all.atom.xml" type="application/atom+xml" title="LeoHung.self() Full Atom Feed"/>

        <title>blogs category // LeoHung.self() // </title>


    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="http://leohung.net/theme/css/pure.css">

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
</head>

<body>
<div class="pure-g-r" id="layout">
<div class="sidebar pure-u">
    <div class="cover-img" style="background-image: url('/images/cover.jpg')">
        <div class="cover-body">
            <header class="header">
                <hgroup>
                    <h1 class="brand-main"><a href="/">LeoHung.self()</a></h1>
                    <p class="tagline"></p>
                    <ul>
                    <li class="links"><a href="http://leohung.net/#education">Education</a></li>
                    <li class="links"><a href="http://leohung.net/#experience">Experience</a></li>
                    <li class="links"><a href="http://leohung.net/#projects">Projects</a></li>
                    <li class="links"><a href="http://leohung.net/#skills">Skills</a></li>
                    <li class="links"><a href="http://leohung.net/#publication">Publication</a></li>
                    <li class="links"><a href="http://leohung.net/archives.html">Blog</a></li>
                    </ul>
                    <p class="social">
                        <a href="https://github.com/LeoHung">
                            <i class="fa fa-github fa-3x"></i>
                        </a>
                    <p>
                </hgroup>
            </header>
        </div>
    </div>
</div>    <div class="pure-u-1">
        <div class="content">
            <!-- A wrapper for all the blog posts -->
            <div class="posts">
                <h1 class="content-subhead">
Posts in 'blogs'                </h1>
<section class="post">
    <header class="post-header">
        <a href="http://leohung.net/author/leo-hung.html" title="See posts by Leo Hung">
        </a>
        <h3><a class="post-title" href="http://leohung.net/fen-bu-shi-ju-liang-ji-jie-xue-xi-xi-tong-mo-xing-mapreduce-data-graph-parameter-server.html">分布式巨量機械學習系統模型: MapReduce, Data Graph, Parameter Server</a></h3>
            <p class="post-meta"><h2>總結</h2>
<p>巨量機械學習需要處理的挑戰有二：(1) 訓練資料集過大 (2) 機械學習模型本身過於複雜，所需要訓練的參數過多。這兩個原因使得無法使用單一主機解決巨量機械學習的問題。為此，許多團隊於近幾年提出分布式機械學習系統，好著手處理巨量資料的挑戰。本篇整理了目前分布式巨量機械學習系統的三種典範：MapReduce, Data Graph, 和 Parameter Server.</p>
<h2>為什麼我們需要分布式系統處理巨量機械學習？</h2>
<p>"巨量"有兩種意義：(1) 訓練資料集過大 (2) 模型本身過度複雜，所需訓練的參數過多。因為這兩個原因，通常無法使用單一機器處理巨量機械學習的問題。為此，開發者得需要設計分布式系統，或者建立在已有的分布式計算框架來處理。</p>
<h2>MapReduce 模式</h2>
<p><center>
<img alt="mapreduce" src="/images/bigml/mapreduce.png" /></p>
<h4>圖片 1. MapReduce  (資料來源: [9])</h4>
<p></center></p>
<p>MapReduce [9] 是很熱門的分布式計算框架, 而 Apache Hadoop [10] 則是對應的開源系統. 一般來說，MapReduce 有兩個階段：Map ...</p></p>
            <p class="post-meta">
                in <a href="http://leohung.net/category/blogs.html">blogs</a> &middot; Wed 13 May 2015
            </p>
    </header>
</section><section class="post">
    <header class="post-header">
        <a href="http://leohung.net/author/leo-hung.html" title="See posts by Leo Hung">
        </a>
        <h3><a class="post-title" href="http://leohung.net/large-scale-distributed-machine-learning-mapreduce-data-graph-and-parameter-server.html">Large-scale Distributed Machine Learning: MapReduce, Data Graph, and Parameter Server</a></h3>
            <p class="post-meta"><h2>Summary</h2>
<p>Big machine learning is hard because (1) the amount of traning data is huge (2) the number of parameters is large. This note summarizes three paradigms of distributed architecture for large-scale machine learning problem: MapReduce, Data Graph, and Parameter Server.</p>
<h2>Why should we build distributed system for large-scale machine ...</h2></p>
            <p class="post-meta">
                in <a href="http://leohung.net/category/blogs.html">blogs</a> &middot; Wed 13 May 2015
            </p>
    </header>
</section><section class="post">
    <header class="post-header">
        <a href="http://leohung.net/author/leo-hung.html" title="See posts by Leo Hung">
        </a>
        <h3><a class="post-title" href="http://leohung.net/networkx-network-discovering-the-core-of-company-network-in-taiwan-by-using-networkx-yong-networkxzhao-chu-tai-wan-gong-si-wang-luo-he-xin-pycon-tw-2014.html">"NetworkX Network: Discovering the core of company network in Taiwan by using NetworkX. (用NetworkX找出台灣公司網絡核心) @ PyCon TW 2014"</a></h3>
            <p class="post-meta"><h1>Slide</h1>
<p><iframe src="http://www.slideshare.net/slideshow/embed_code/34775422" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/AskusHong/pycon2014" title="NetworkX Network: 用NetworkX找出台灣公司網絡核心 by Leo Hung @PyCon TW 2014" target="_blank">NetworkX Network: 用NetworkX找出台灣公司網絡核心 by Leo Hung @PyCon TW 2014</a> </strong> from <strong><a href="http://www.slideshare.net/AskusHong" target="_blank">SanChan Hong</a></strong> </div></p>
<h1>Code</h1>
<p><a href="https://github.com/LeoHung/pycon2014_tw_company_core_network">Github Link</a></p>
<h1>Result</h1>
<p><img alt="Closeness" src="/images/closeness_50.png" /></p></p>
            <p class="post-meta">
                in <a href="http://leohung.net/category/blogs.html">blogs</a> &middot; Sat 17 May 2014
            </p>
    </header>
</section><section class="post">
    <header class="post-header">
        <a href="http://leohung.net/author/leo-hung.html" title="See posts by Leo Hung">
        </a>
        <h3><a class="post-title" href="http://leohung.net/teaching-elasticsearch-reading-chinese-in-1-minutes.html">"Teaching Elasticsearch reading Chinese in 1 Minutes "</a></h3>
            <p class="post-meta"><h1>Teaching Elasticsearch reading Chinese in 1 Minutes</h1>
<p>Elasticsearch(es) is a powerful open source solution for searching, which is serving in wikipedia currently; however, Chinese users is not so lucky with es, becasue the default analyzer of es cannot deal with Chinese well, which will tokenzie Chinese sentences into individual ...</p></p>
            <p class="post-meta">
                in <a href="http://leohung.net/category/blogs.html">blogs</a> &middot; Sat 26 April 2014
            </p>
    </header>
</section><section class="post">
    <header class="post-header">
        <a href="http://leohung.net/author/leohung.html" title="See posts by leohung">
        </a>
        <h3><a class="post-title" href="http://leohung.net/semi-supervised-hashing-for-scalable-image-retrieval.html">"Semi-Supervised Hashing for Scalable Image Retrieval"</a></h3>
            <p class="post-meta"><p>J. Wang et al, "Semi-Supervised Hashing for Scalable Image Retrieval," CVPR, 2010.</p>
<p>The following figures and formula are all copied from this paper.</p>
<h2>Novelty</h2>
<p>Unsupervised learning method, like LSH, would ignore the relationship of labels; however, supervised learning method modified from LSH, like RBM or SH, would cost time to ...</p></p>
            <p class="post-meta">
                in <a href="http://leohung.net/category/blogs.html">blogs</a> &middot; Sun 08 September 2013
            </p>
    </header>
</section><section class="post">
    <header class="post-header">
        <a href="http://leohung.net/author/leohung.html" title="See posts by leohung">
        </a>
        <h3><a class="post-title" href="http://leohung.net/mairal-et-al-online-dictionary-learning-for-sparse-coding.html">"Mairal et al. Online dictionary learning for sparse coding"</a></h3>
            <p class="post-meta"><p>Mairal et al. Online dictionary learning for sparse coding. ICML 2009.</p>
<p>The following figures are all from this paper.</p>
<p>The paper goal is to propose a online learning method to learn sparse coding dictionary, the basis set which can represent specific data through linear combination, for large scale data.</p>
<h2>Algorithm ...</h2></p>
            <p class="post-meta">
                in <a href="http://leohung.net/category/blogs.html">blogs</a> &middot; Sun 08 September 2013
            </p>
    </header>
</section><section class="post">
    <header class="post-header">
        <a href="http://leohung.net/author/leohung.html" title="See posts by leohung">
        </a>
        <h3><a class="post-title" href="http://leohung.net/aggregating-local-descriptors-into-a-compact-image-representation.html">"Aggregating local descriptors into a compact image representation"</a></h3>
            <p class="post-meta"><p>Herve Jegou, et al., Aggregating local descriptors into a compact image representation, Proc. IEEE CVPR'10
The goal of the work is reducing the computing time and the memory usage without lossing too much accuracy in image retrieval for large scale data. This work consists of two parts: VLAD and ...</p></p>
            <p class="post-meta">
                in <a href="http://leohung.net/category/blogs.html">blogs</a> &middot; Sun 08 September 2013
            </p>
    </header>
</section><section class="post">
    <header class="post-header">
        <a href="http://leohung.net/author/leohung.html" title="See posts by leohung">
        </a>
        <h3><a class="post-title" href="http://leohung.net/efficient-visual-search-of-videos-cast-as-text-retrieval.html">"Efficient visual search of videos cast as text retrieval"</a></h3>
            <p class="post-meta"><p>"Efficient visual search of videos cast as text retrieval," J. Sivic, and A. Zisserman, IEEE TPAMI, 2009
Paper Authors: Josef Sivic and Andrew Zisserman The following figures are all from this paper.</p>
<p><img alt="outline" src="/images/ammai/03/outline.png" /></p>
<p>J. Sivic, and A. Zisserman proposed this method which analogizes searching in video to in text corpora: representing ...</p></p>
            <p class="post-meta">
                in <a href="http://leohung.net/category/blogs.html">blogs</a> &middot; Sun 08 September 2013
            </p>
    </header>
</section><section class="post">
    <header class="post-header">
        <a href="http://leohung.net/author/leohung.html" title="See posts by leohung">
        </a>
        <h3><a class="post-title" href="http://leohung.net/distinctive-image-features-from-scale-invariant-keypoints.html">"Distinctive Image Features from Scale-Invariant Keypoints"</a></h3>
            <p class="post-meta"><p>"Distinctive Image Features from Scale-Invariant Keypoints," Lowe, IJCV, 2004</p>
<p><a href="http://mslab.csie.ntu.edu.tw/~askus/ammai/blog/wp-content/uploads/2012/03/螢幕快照-2012-03-13-下午11.11.08.png"> </a></p>
<p>Paper author: David G. Lowe The following figures are all from this paper.</p>
<h2>Novelties, contributions, assumption</h2>
<p>This work introduce a set of promising affine invariant features, which can be used to identified specific object varied with background, illumination, rotation degree.</p>
<h2>Questions ...</h2></p>
            <p class="post-meta">
                in <a href="http://leohung.net/category/blogs.html">blogs</a> &middot; Sun 08 September 2013
            </p>
    </header>
</section><section class="post">
    <header class="post-header">
        <a href="http://leohung.net/author/leohung.html" title="See posts by leohung">
        </a>
        <h3><a class="post-title" href="http://leohung.net/plsi-lda.html">"PLSI &amp; LDA"</a></h3>
            <p class="post-meta"><p>PLSI &amp; LDA</p>
<p>Origin source: "Probabilistic latent semantic indexing," T. Hofmann, SIGIR, 1999. "Latent Dirichlet allocation," D. Blei, A. Ng, and M. Jordan. . Journal of Machine Learning Research, 3:993–1022, January 2003 The following figures and formula are copied from above papers.</p>
<p>PLSI and LDA are both hidden-class decomposition method ...</p></p>
            <p class="post-meta">
                in <a href="http://leohung.net/category/blogs.html">blogs</a> &middot; Sat 07 September 2013
            </p>
    </header>
</section><div class="pagination-wrapper content-subhead">
    <div class="pagination">
        <div class="pagination-left">
                &nbsp;
        </div>
        <span>Page 1 / 2</span>
        <div class="pagination-right">
                <a href="http://leohung.net/category/blogs2.html">Older posts&nbsp;&rarr;</a>
        </div>
    </div>
</div><footer class="footer">
    <p>&copy; LeoHung.self() &ndash;
        Built with <a href="https://github.com/PurePelicanTheme/pure">Pure Theme</a>
        for <a href="http://blog.getpelican.com/">Pelican</a>
    </p>
</footer>            </div>
        </div>
    </div>
</div>
    <script>
        var $top = $('.go-top');

        // Show or hide the sticky footer button
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                $top.fadeIn(200);
            } else {
                $top.fadeOut(200);
            }
        });

        // Animate the scroll to top
        $top.click(function(event) {
            event.preventDefault();
            $('html, body').animate({scrollTop: 0}, 300);
        })

        // Makes sure that the href="#" attached to the <a> elements
        // don't scroll you back up the page.
        $('body').on('click', 'a[href="#"]', function(event) {
            event.preventDefault();
        });
    </script>
</body>
</html>